#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""éŸ³å£°å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""

import os
import logging
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from pydub import AudioSegment

logger = logging.getLogger(__name__)

# CPUæœ€é©åŒ–
CPU_COUNT = multiprocessing.cpu_count()
logger.info(f"ğŸ’» CPU: {CPU_COUNT}ã‚³ã‚¢æ¤œå‡º")


class AudioProcessor:
    """éŸ³å£°å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.output_dir = "output"
        os.makedirs(self.output_dir, exist_ok=True)
        
    def process_audio(self, segments, fade_in, fade_out, crossfade, target_volume, output_name="final_audio.mp3", target_duration_minutes=None):
        """è¤‡æ•°éŸ³æºã‚’çµåˆï¼ˆä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–ï¼‰"""
        logger.info(f"ğŸ”§ {len(segments)}å€‹ã®éŸ³æºã‚’çµåˆ...")
        
        # ä¸¦åˆ—ã§éŸ³æºã‚’èª­ã¿è¾¼ã¿ãƒ»å‡¦ç†ï¼ˆé«˜é€ŸåŒ–ï¼‰
        if len(segments) > 3:
            logger.info(f"âš¡ ä¸¦åˆ—å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {min(CPU_COUNT, len(segments))}ã‚¹ãƒ¬ãƒƒãƒ‰")
            processed_segments = self._parallel_load_and_process(segments, target_volume, fade_in)
        else:
            processed_segments = self._sequential_load_and_process(segments, target_volume, fade_in)
        
        # çµåˆ
        combined = processed_segments[0]
        for audio in processed_segments[1:]:
            combined = combined.append(audio, crossfade=crossfade * 1000)
        
        # ç›®æ¨™æ™‚é–“ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãƒ«ãƒ¼ãƒ—å‡¦ç†
        if target_duration_minutes:
            target_duration_ms = int(target_duration_minutes * 60 * 1000)  # åˆ†â†’ãƒŸãƒªç§’ï¼ˆæ•´æ•°åŒ–ï¼‰
            current_duration_ms = len(combined)
            
            logger.info(f"ğŸ“ ç¾åœ¨ã®é•·ã•: {current_duration_ms / 1000 / 60:.1f}åˆ†")
            logger.info(f"ğŸ¯ ç›®æ¨™ã®é•·ã•: {target_duration_minutes}åˆ†")
            
            if current_duration_ms < target_duration_ms:
                # çŸ­ã„å ´åˆï¼šãƒ«ãƒ¼ãƒ—ã—ã¦å»¶é•·ï¼ˆãƒãƒ£ãƒ³ã‚¯æ–¹å¼ã§åŠ¹ç‡åŒ–ï¼‰
                logger.info(f"ğŸ”„ ç›®æ¨™æ™‚é–“ã¾ã§è‡ªå‹•ãƒ«ãƒ¼ãƒ—ä¸­...")
                base_audio = combined  # ãƒ«ãƒ¼ãƒ—ç”¨ã®åŸºæœ¬éŸ³æºã‚’ä¿å­˜
                base_duration_ms = len(base_audio)
                
                # å¿…è¦ãªãƒ«ãƒ¼ãƒ—å›æ•°ã‚’è¨ˆç®—
                loops_needed = (target_duration_ms - current_duration_ms) // base_duration_ms
                remaining_ms = target_duration_ms - current_duration_ms - (loops_needed * base_duration_ms)
                
                logger.info(f"  ğŸ“Š ãƒ«ãƒ¼ãƒ—å›æ•°: {loops_needed}å› + ç«¯æ•°{remaining_ms/1000:.1f}ç§’")
                
                # ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ ï¼ˆå¤§ããªãƒãƒ£ãƒ³ã‚¯ã§å‡¦ç†ï¼‰
                for loop_num in range(int(loops_needed)):
                    combined = combined.append(base_audio, crossfade=crossfade * 1000)
                    if (loop_num + 1) % 5 == 0:  # 5å›ã”ã¨ã«é€²æ—è¡¨ç¤º
                        logger.info(f"  â†’ {len(combined) / 1000 / 60:.1f}åˆ† / {target_duration_minutes}åˆ†")
                
                # ç«¯æ•°ãŒã‚ã‚Œã°è¿½åŠ 
                if remaining_ms > 0:
                    partial_audio = base_audio[:int(remaining_ms)]
                    combined = combined.append(partial_audio, crossfade=crossfade * 1000)
                
                logger.info(f"âœ“ ãƒ«ãƒ¼ãƒ—å®Œäº†: {len(combined) / 1000 / 60:.1f}åˆ†")
            
            elif current_duration_ms > target_duration_ms:
                # é•·ã„å ´åˆï¼šç›®æ¨™æ™‚é–“ã§åˆ‡ã‚Šå–ã‚Š
                logger.info(f"âœ‚ï¸ ç›®æ¨™æ™‚é–“ã§åˆ‡ã‚Šå–ã‚Šä¸­...")
                combined = combined[:int(target_duration_ms)]
                logger.info(f"âœ“ åˆ‡ã‚Šå–ã‚Šå®Œäº†: {len(combined) / 1000 / 60:.1f}åˆ†")
        
        # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
        combined = combined.fade_out(fade_out * 1000)
        
        output_path = os.path.join(self.output_dir, output_name)
        final_duration_minutes = len(combined) / 1000 / 60
        
        # é•·å°ºéŸ³æºã®å ´åˆã¯ä½ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆã§è»½é‡åŒ–
        if final_duration_minutes > 180:  # 3æ™‚é–“ä»¥ä¸Š
            logger.info(f"âš ï¸ é•·å°ºéŸ³æºã®ãŸã‚192kbpsã§å‡ºåŠ›ã—ã¾ã™")
            bitrate = "192k"
        else:
            bitrate = "320k"
        
        logger.info(f"ğŸ’¾ MP3ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­ï¼ˆ{final_duration_minutes:.1f}åˆ†ï¼‰...")
        
        # è¶…é•·å°ºã®å ´åˆã¯åˆ†å‰²ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆWAVãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™å›é¿ï¼‰
        if final_duration_minutes > 240:  # 4æ™‚é–“ä»¥ä¸Š
            logger.info(f"ğŸ”„ è¶…é•·å°ºã®ãŸã‚åˆ†å‰²ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ–¹å¼ã‚’ä½¿ç”¨")
            self._export_long_audio(combined, output_path, bitrate, final_duration_minutes)
        else:
            # é€šå¸¸ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            combined.export(output_path, format="mp3", bitrate=bitrate, parameters=["-q:a", "2"])
        
        logger.info(f"âœ“ éŸ³å£°å‡¦ç†å®Œäº†: {output_path} ({final_duration_minutes:.1f}åˆ†)")
        return output_path
    
    def _load_and_process_segment(self, args):
        """å˜ä¸€éŸ³æºã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰"""
        segment_path, target_volume, fade_in, index = args
        
        try:
            audio = AudioSegment.from_file(segment_path)
            
            # éŸ³é‡èª¿æ•´
            current_db = audio.dBFS
            gain = target_volume - current_db
            audio = audio.apply_gain(gain)
            
            # æœ€åˆã®éŸ³æºã®ã¿ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
            if index == 0:
                audio = audio.fade_in(fade_in * 1000)
            
            return (index, audio)
        except Exception as e:
            logger.error(f"âŒ éŸ³æºèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ [{segment_path}]: {e}")
            return (index, None)
    
    def _parallel_load_and_process(self, segments, target_volume, fade_in):
        """ä¸¦åˆ—ã§éŸ³æºã‚’èª­ã¿è¾¼ã¿ãƒ»å‡¦ç†"""
        max_workers = min(CPU_COUNT, len(segments))
        
        # å¼•æ•°ã‚’æº–å‚™
        args_list = [(seg, target_volume, fade_in, i) for i, seg in enumerate(segments)]
        
        # ä¸¦åˆ—å‡¦ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            results = list(executor.map(self._load_and_process_segment, args_list))
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã«ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x[0])
        
        # Noneã‚’é™¤å¤–
        processed = [audio for idx, audio in results if audio is not None]
        
        logger.info(f"âœ“ ä¸¦åˆ—èª­ã¿è¾¼ã¿å®Œäº†: {len(processed)}/{len(segments)}å€‹")
        return processed
    
    def _sequential_load_and_process(self, segments, target_volume, fade_in):
        """é€æ¬¡å‡¦ç†ï¼ˆéŸ³æºãŒå°‘ãªã„å ´åˆï¼‰"""
        processed = []
        
        for i, segment_path in enumerate(segments):
            audio = AudioSegment.from_file(segment_path)
            
            # éŸ³é‡èª¿æ•´
            current_db = audio.dBFS
            gain = target_volume - current_db
            audio = audio.apply_gain(gain)
            
            if i == 0:
                audio = audio.fade_in(fade_in * 1000)
            
            processed.append(audio)
        
        return processed
    
    def _export_long_audio(self, audio_segment, output_path, bitrate, duration_minutes):
        """è¶…é•·å°ºéŸ³æºã‚’åˆ†å‰²ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        import tempfile
        import subprocess
        
        # 60åˆ†ã”ã¨ã«åˆ†å‰²
        chunk_duration_ms = 60 * 60 * 1000  # 60åˆ†
        total_duration_ms = len(audio_segment)
        num_chunks = (total_duration_ms + chunk_duration_ms - 1) // chunk_duration_ms
        
        logger.info(f"  ğŸ“¦ {num_chunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²...")
        
        temp_files = []
        temp_dir = tempfile.gettempdir()
        
        try:
            # ä¸¦åˆ—ã§ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆé«˜é€ŸåŒ–ï¼‰
            def export_chunk(args):
                i, start_ms, end_ms = args
                chunk = audio_segment[start_ms:end_ms]
                temp_file = os.path.join(temp_dir, f"chunk_{i:03d}.mp3")
                chunk.export(temp_file, format="mp3", bitrate=bitrate, parameters=["-q:a", "2"])
                return temp_file
            
            # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ã‚’æº–å‚™
            chunk_args = [
                (i, i * chunk_duration_ms, min((i + 1) * chunk_duration_ms, total_duration_ms))
                for i in range(num_chunks)
            ]
            
            # ä¸¦åˆ—ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            max_workers = min(CPU_COUNT, num_chunks)
            logger.info(f"  âš¡ ä¸¦åˆ—ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {max_workers}ã‚¹ãƒ¬ãƒƒãƒ‰")
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                temp_files = list(executor.map(export_chunk, chunk_args))
                for i, _ in enumerate(temp_files):
                    if (i + 1) % 4 == 0 or i == len(temp_files) - 1:
                        logger.info(f"    â†’ ãƒãƒ£ãƒ³ã‚¯ {i+1}/{num_chunks} å®Œäº†")
            
            # ffmpegã§çµåˆ
            logger.info(f"  ğŸ”— ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆä¸­...")
            
            # concatç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆä½œæˆ
            concat_file = os.path.join(temp_dir, "concat_list.txt")
            with open(concat_file, 'w', encoding='utf-8') as f:
                for temp_file in temp_files:
                    # Windowsãƒ‘ã‚¹ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                    escaped_path = temp_file.replace('\\', '/')
                    f.write(f"file '{escaped_path}'\n")
            
            # ffmpegã§çµåˆ
            cmd = [
                'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
                '-i', concat_file,
                '-c', 'copy',  # å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãªã—ï¼ˆé«˜é€Ÿï¼‰
                output_path
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            logger.info(f"  âœ“ çµåˆå®Œäº†")
            
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            for temp_file in temp_files:
                try:
                    os.remove(temp_file)
                except:
                    pass
            try:
                os.remove(concat_file)
            except:
                pass

